{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_04 - Autoencoders.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqOrnxrpYFy9"
      },
      "source": [
        "# **Autoencoders tutorial**\n",
        "In today's tutorial you will learn how to use autoencoders to solve the following tasks:\n",
        "- dimensionality reduction;\n",
        "- image denoising;\n",
        "- anomaly detection.\n",
        "\n",
        "We will use [**TensorFlow**](https://ekababisong.org/gcp-ml-seminar/tensorflow/) framework and [**Keras**](https://keras.io/) open-source library to rapidly prototype deep neural networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPpiRdjxqPO9"
      },
      "source": [
        "# **Preliminary operations**\n",
        "The following code downloads all the necessary material into the remote machine. At the end of the execution select the **File** tab to verify that everything has been correctly downloaded."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zl-ByJkmYEk0"
      },
      "source": [
        "!wget https://biolab.csr.unibo.it/ferrara/Courses/DL/Tutorials/Autoencoders/creditcard.zip\n",
        "\n",
        "!unzip creditcard.zip\n",
        "\n",
        "!rm creditcard.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1o8ZChPhCrI"
      },
      "source": [
        "# **Useful modules import**\n",
        "First of all, it is necessary to import useful modules used during the tutorial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1DEyFzkdN9u"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UF7IBOzqULRt"
      },
      "source": [
        "# **Utility functions**\n",
        "Execute the following code to define some utility functions used in the tutorial:\n",
        "- **plot_2d_data** plots 2D labeled data;\n",
        "- **plot_history** draws in a graph the loss trend over epochs on both training and validation sets. Moreover, if provided, it draws in the same graph also the trend of the given metric;\n",
        "- **show_confusion_matrix** visualizes a 2D confusion matrix as a color-coded image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScuGEab6UM0d"
      },
      "source": [
        "def plot_2d_data(data_2d,y,titles=None,figsize=(7,7)):\n",
        "  _,axs=plt.subplots(1,len(data_2d),figsize=figsize)\n",
        "\n",
        "  for i in range(len(data_2d)):\n",
        "    if (titles!=None):\n",
        "      axs[i].set_title(titles[i])\n",
        "    scatter=axs[i].scatter(data_2d[i][:,0],data_2d[i][:,1],s=1,c=y[i],cmap=plt.cm.Paired)\n",
        "    axs[i].legend(*scatter.legend_elements())\n",
        "\n",
        "def plot_history(history,metric=None):\n",
        "  fig, ax1 = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "  epoch_count=len(history.history['loss'])\n",
        "\n",
        "  line1,=ax1.plot(range(1,epoch_count+1),history.history['loss'],label='train_loss',color='orange')\n",
        "  ax1.plot(range(1,epoch_count+1),history.history['val_loss'],label='val_loss',color = line1.get_color(), linestyle = '--')\n",
        "  ax1.set_xlim([1,epoch_count])\n",
        "  ax1.set_ylim([0, max(max(history.history['loss']),max(history.history['val_loss']))])\n",
        "  ax1.set_ylabel('loss',color = line1.get_color())\n",
        "  ax1.tick_params(axis='y', labelcolor=line1.get_color())\n",
        "  ax1.set_xlabel('Epochs')\n",
        "  _=ax1.legend(loc='lower left')\n",
        "\n",
        "  if (metric!=None):\n",
        "    ax2 = ax1.twinx()\n",
        "    line2,=ax2.plot(range(1,epoch_count+1),history.history[metric],label='train_'+metric)\n",
        "    ax2.plot(range(1,epoch_count+1),history.history['val_'+metric],label='val_'+metric,color = line2.get_color(), linestyle = '--')\n",
        "    ax2.set_ylim([0, max(max(history.history[metric]),max(history.history['val_'+metric]))])\n",
        "    ax2.set_ylabel(metric,color=line2.get_color())\n",
        "    ax2.tick_params(axis='y', labelcolor=line2.get_color())\n",
        "    _=ax2.legend(loc='upper right')\n",
        "\n",
        "def show_confusion_matrix(conf_matrix,class_names,figsize=(10,10)):\n",
        "  fig, ax = plt.subplots(figsize=figsize)\n",
        "  img=ax.matshow(conf_matrix)\n",
        "  tick_marks = np.arange(len(class_names))\n",
        "  _=plt.xticks(tick_marks, class_names,rotation=45)\n",
        "  _=plt.yticks(tick_marks, class_names)\n",
        "  _=plt.ylabel('Real')\n",
        "  _=plt.xlabel('Predicted')\n",
        "  \n",
        "  for i in range(len(class_names)):\n",
        "    for j in range(len(class_names)):\n",
        "        text = ax.text(j, i, '{0:.1%}'.format(conf_matrix[i, j]),\n",
        "                       ha='center', va='center', color='w')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SE7kwKmmpr3V"
      },
      "source": [
        "# **Dimensionality reduction**\n",
        "In this section a concrete example on how autoencoders can be used for dimensionality reduction is provided."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrd7RTh1uuHe"
      },
      "source": [
        "## **Dataset**\n",
        "The [**digits MNIST**](http://yann.lecun.com/exdb/mnist/) dataset, containing 28x28 grayscale images of the 10 digits, will be used.\n",
        "\n",
        "The goal is to reduce the dimensions, from 784 (28x28) to 2, by including as much information as possible.\n",
        "\n",
        "The following code loads in memory the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkQzdximhFJp"
      },
      "source": [
        "(train_x, train_y), (test_x, test_y) = keras.datasets.mnist.load_data()\n",
        "\n",
        "print('Train shape: ',train_x.shape)\n",
        "print('Test shape: ',test_x.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkyD9DVmxUbn"
      },
      "source": [
        "### **Visualization**\n",
        "Randomly selected images can be shown by executing the following code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cj4HEz-QxaKd"
      },
      "source": [
        "image_count=10\n",
        "\n",
        "_, axs = plt.subplots(1, image_count,figsize=(15, 10))\n",
        "for i in range(image_count):\n",
        "  random_idx=random.randint(0,train_x.shape[0])\n",
        "  axs[i].imshow(train_x[random_idx],cmap='gray')\n",
        "  axs[i].axis('off')\n",
        "  axs[i].set_title(train_y[random_idx])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBH5sGlphLW4"
      },
      "source": [
        "### **Intensity range normalization**\n",
        "Pixel intensity is usually represented as discrete values in the range [0;255]. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zd2n62-Dv7WA"
      },
      "source": [
        "print('Min value: ',train_x.min())\n",
        "print('Max value: ',train_x.max())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSXwSidVwMp2"
      },
      "source": [
        "Such values could produce math range errors with the activation function or make training unstable. To overcome these issues, a simple normalization step can be applied by dividing all values by 255 to get continuous values in the range [0;1]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bt1vphGXhKWg"
      },
      "source": [
        "train_x = train_x/255.0\n",
        "test_x = test_x/255.0\n",
        "\n",
        "print('Min value: ',train_x.min())\n",
        "print('Max value: ',train_x.max())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urdAfws0xxhf"
      },
      "source": [
        "### **Image linearization**\n",
        "The images need to be converted from 2D matrices to vectors before they can be used as input of dimensionality reduction algorithms (e.g., PCA).\n",
        "\n",
        "The following code use the Numpy function [**reshape**](https://numpy.org/doc/stable/reference/generated/numpy.reshape.html) to flatten the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luSNMZzsovwj"
      },
      "source": [
        "train_x_flatten=np.reshape(train_x,(train_x.shape[0],-1))\n",
        "test_x_flatten=np.reshape(test_x,(test_x.shape[0],-1))\n",
        "\n",
        "print('Train flatten shape: ',train_x_flatten.shape)\n",
        "print('Test flatten shape: ',test_x_flatten.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0cl05lZj5mH"
      },
      "source": [
        "## **Principal component analysis**\n",
        "*Principal Component Analysis* (PCA) is a method widely used to apply a linear dimensionality reduction to large datasets.\n",
        "\n",
        "This algorithm can be easily applied to a dataset using the class [**PCA**](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) provided by the Scikit-learn library.\n",
        "\n",
        "The *n_components* parameter is used to set the number of dimensions of the reduced space."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1skhdMHkW7n"
      },
      "source": [
        "pca = PCA(n_components=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5jbJQ-w3n1_"
      },
      "source": [
        "The [**fit**](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA.fit) method can be used to fit the PCA model to the data passed as input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rwCdFMu3oQ6"
      },
      "source": [
        "pca.fit(train_x_flatten)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hlpjlhU33Mz"
      },
      "source": [
        "Once the PCA model has been created, the dimensionality reduction can be applied to a dataset using the [**transform**](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA.transform) method.   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bv-4k78kjx4"
      },
      "source": [
        "pca_encoded_train_x=pca.transform(train_x_flatten)\n",
        "pca_encoded_test_x=pca.transform(test_x_flatten)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Pu_DVB147my"
      },
      "source": [
        "### **Reduced space visualization**\n",
        "The following code visualize the reduced training and test sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3At1b5Mf6jFM"
      },
      "source": [
        "plot_2d_data([pca_encoded_train_x,pca_encoded_test_x],[train_y,test_y],['Train','Test'],(15,7))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IskqQpLY3Fr"
      },
      "source": [
        "### **Reconstructed images**\n",
        "Reduced images can be reconstructed using the [**inverse_transform**](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA.inverse_transform) method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5ECGfRxf0my"
      },
      "source": [
        "pca_decoded_test_x_flatten=pca.inverse_transform(pca_encoded_test_x)\n",
        "\n",
        "print('PCA decoded test flatten shape: ',pca_decoded_test_x_flatten.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GRa_mem9fA7"
      },
      "source": [
        "Before visualizing the reconstructed images, it is necessary to return to their original 2D shape."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2L4lflE8-lVq"
      },
      "source": [
        "pca_decoded_test_x=np.reshape(pca_decoded_test_x_flatten,(test_x.shape[0],test_x.shape[1],test_x.shape[2]))\n",
        "\n",
        "print('PCA decoded test shape: ',pca_decoded_test_x.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLoW1ctd-QTk"
      },
      "source": [
        "Randomly selected images and the corresponding reconstructed version can be shown executing the following code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uAlDPYd-vlN"
      },
      "source": [
        "n=5\n",
        "\n",
        "fig, axs = plt.subplots(n, 2,figsize=(4,6))\n",
        "axs[0,0].set_title('Original image')\n",
        "axs[0,1].set_title('PCA')\n",
        "for i in range(n):\n",
        "  rnd_idx=random.randint(0,test_x.shape[0]-1)\n",
        "\n",
        "  axs[i,0].axis('off')\n",
        "  axs[i,0].imshow(test_x[rnd_idx], cmap='gray')\n",
        "\n",
        "  axs[i,1].axis('off')\n",
        "  axs[i,1].imshow(pca_decoded_test_x[rnd_idx], cmap='gray')\n",
        "  \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZhVBsrO-93s"
      },
      "source": [
        "## **Undercomplete autoencoder**\n",
        "In this section an undercomplete autoencoder is implemented to compare its reduction ability with PCA."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6puuu0XDAUe1"
      },
      "source": [
        "### **Model definition**\n",
        "The following function creates an undercomplete autoencoder given:\n",
        "- the number of input features (*input_count*);\n",
        "- the number of neurons for each hidden layer (*neuron_count_per_hidden_layer*);\n",
        "- the dimension of the latent space (*encoded_dim*);\n",
        "- the string identifier of the activation function of the hidden layers (*hidden_activation*);\n",
        "- the string identifier of the activation function of the output layer (*output_activation*).\n",
        "\n",
        "In Keras, a sequential is a stack of layers where each layer has exactly one input and one output. It can be created by passing a list of layers to the  constructor [**keras.Sequential**](https://keras.io/guides/sequential_model/).\n",
        "\n",
        "[**Keras layers API**](https://keras.io/api/layers/) offers a wide range of built-in layers ready for use, including:\n",
        "- [**Input**](https://keras.io/api/layers/core_layers/input/) - the input of the model. Note that, you can also omit the **Input** layer. In that case the model doesn't have any weights until the first call to a training/evaluation method (since it is not yet built);\n",
        "- [**Dense**](https://keras.io/api/layers/core_layers/dense/) - a fully-connected layer.\n",
        "\n",
        "To combine encoder and decoder together forming the autoencoder, the [**Model**](https://keras.io/api/models/model/) class provided by Keras is used. Input and output layers are passed to the constructor, then it groups layers into an object with training and inference features.\n",
        "\n",
        "<u>Note that, the **build_autoencoder** function returns the encoder and the decoder models as well as the whole autoencoder.</u>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kTIOHjjzMwW"
      },
      "source": [
        "def build_autoencoder(input_count,neuron_count_per_hidden_layer,encoded_dim,hidden_activation,output_activation):\n",
        "  #Encoder\n",
        "  encoder = keras.Sequential(name='encoder')\n",
        "  input_layer=layers.Input(shape=input_count,name='encoder_input');\n",
        "  encoder.add(input_layer)\n",
        "    \n",
        "  for neuron_count in neuron_count_per_hidden_layer:\n",
        "    hidden_layer=layers.Dense(neuron_count,activation=hidden_activation)\n",
        "    encoder.add(hidden_layer)\n",
        "      \n",
        "  latent_layer=layers.Dense(encoded_dim,activation=hidden_activation)\n",
        "  encoder.add(latent_layer)\n",
        "    \n",
        "  #Decoder\n",
        "  decoder = keras.Sequential(name='decoder')\n",
        "  decoder.add(layers.Input(shape=encoded_dim))\n",
        "  \n",
        "  for neuron_count in reversed(neuron_count_per_hidden_layer):\n",
        "    hidden_layer=layers.Dense(neuron_count,activation=hidden_activation)\n",
        "    decoder.add(hidden_layer)\n",
        "      \n",
        "  output_layer=layers.Dense(input_count,activation=output_activation)\n",
        "  decoder.add(output_layer)\n",
        "  \n",
        "  autoencoder=keras.Model(encoder.input,decoder(encoder.output),name='autoencoder')\n",
        "    \n",
        "  return autoencoder,encoder,decoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SytWQHJTBsam"
      },
      "source": [
        "### **Model creation**\n",
        "The following code creates an undercomplete autoencoder by calling the **build_autoencoder** function defined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tizUSgS8nl5I"
      },
      "source": [
        "autoencoder,encoder,decoder=build_autoencoder(train_x_flatten.shape[1],[512,256,128],2,'elu','sigmoid')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iydWhuZZEQZP"
      },
      "source": [
        "### **Model visualization**\n",
        "A string summary of the network can be printed using the [**summary**](https://keras.io/api/models/model/#summary-method) method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvHnwhnUCIcB"
      },
      "source": [
        "autoencoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OO8cQ4LBEwoX"
      },
      "source": [
        "The summary is useful for simple models, but can be confusing for complex models.\n",
        "\n",
        "Function [**keras.utils.plot_model**](https://keras.io/api/utils/model_plotting_utils/) creates a plot of the neural network graph that can make more complex models easier to understand."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLVmhpTxCBo2"
      },
      "source": [
        "keras.utils.plot_model(autoencoder,show_shapes=True, show_layer_names=False,expand_nested=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xth8tpFBE9ut"
      },
      "source": [
        "### **Model compilation**\n",
        "The compilation is the final step in configuring the model for training. \n",
        "\n",
        "The following code use the [**compile**](https://keras.io/api/models/model_training_apis/#compile-method) method to compile the model.\n",
        "The important arguments are:\n",
        "- the optimization algorithm (*optimizer*);\n",
        "- the loss function (*loss*);\n",
        "- the metrics used to evaluate the performance of the model (*metrics*).\n",
        "\n",
        "The most common [optimization algorithms](https://keras.io/api/optimizers/#available-optimizers), [loss functions](https://keras.io/api/losses/#available-losses) and [metrics](https://keras.io/api/metrics/#available-metrics) are already available in Keras. You can either pass them to **compile** as an instance or by the corresponding string identifier. In the latter case, the default parameters will be used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHs9OdwUhw95"
      },
      "source": [
        "autoencoder.compile(loss='mse', optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZrICGel_9Xk"
      },
      "source": [
        "### **Split data into training and validation sets**\n",
        "In order to avoid overfitting during training, it is necessary to have a separate dataset (called validation set), in addition to the training and test datasets, to choose the optimal value for the hyperparameters.\n",
        "\n",
        "For this reason, *train_x* and *train_y* are divided into training and validation sets using the [**train_test_split**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function provided by Scikit-learn.\n",
        "\n",
        "The *val_size* variable represents the percentage (or the absolute number) of patterns to include in the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12muVOUFAFkC"
      },
      "source": [
        "val_size=10000\n",
        "\n",
        "train_x_flatten, val_x_flatten, train_y, val_y = train_test_split(train_x_flatten, train_y, test_size = val_size,random_state = 1,shuffle=True)\n",
        "\n",
        "print('Train data flatten shape: ',train_x_flatten.shape)\n",
        "print('Train label shape: ',train_y.shape)\n",
        "print('Validation data flatten shape: ',val_x_flatten.shape)\n",
        "print('Validation label shape: ',val_y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiizsSCoFyra"
      },
      "source": [
        "### **Training**\n",
        "Now we are ready to train our model by calling the [**fit**](https://keras.io/api/models/model_training_apis/#fit-method) method.\n",
        "\n",
        "It trains the model for a fixed number of epochs (*epoch_count*) using the training set (*train_x_flatten*) divided into mini-batches of *batch_size* elements. During the training process, the performances will be evaluated on both training and validation (*val_x_flatten*) sets.\n",
        "\n",
        "Break training when a metric or the loss has stopped improving on the validation set, helps to avoid overfitting.\n",
        "\n",
        "For this purpose, Keras provides a class called [**EarlyStopping**](https://keras.io/api/callbacks/early_stopping/). Important class parameters are:\n",
        "- *monitor* - the name of the metric or the loss to be observed; \n",
        "- *patience* - the number of epochs with no improvement after which training will be stopped;\n",
        "- *restore_best_weights* - whether to restore model weights from the epoch with the best value of the monitored quantity.\n",
        "\n",
        "Once created an instance of the **EarlyStopping** class, it can be passed to the **fit** method in the *callbacks* parameter.\n",
        "\n",
        "<u>Note that, in this case the target data correspond to the input data because the objective of the autoencoder is to reconstruct the input as best as possible.</u>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPVP_oLih4jY"
      },
      "source": [
        "epoch_count = 100\n",
        "batch_size=128\n",
        "patience=5\n",
        "\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
        "\n",
        "history = autoencoder.fit(train_x_flatten,train_x_flatten,validation_data=(val_x_flatten,val_x_flatten),epochs=epoch_count,batch_size=batch_size,callbacks=[early_stop])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXl2nFDAIkT5"
      },
      "source": [
        "We can learn a lot about our model by observing the graph of its performance over time during training.\n",
        "\n",
        "The **fit** method returns an object (*history*) containing loss and metrics values at successive epochs for both training and validation sets.\n",
        "\n",
        "The following code calls the **plot_history** function defined above to draw in a graph the loss over epochs on both training and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnGpyfS7ItPU"
      },
      "source": [
        "plot_history(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUP_D4vLzSI0"
      },
      "source": [
        "### **Performance evaluation on the test set**\n",
        "The performance on the test set can be easily measured by calling the **evaluate** method of the autoencoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbkf5TmIzW24"
      },
      "source": [
        "test_loss = autoencoder.evaluate(test_x_flatten, test_x_flatten, batch_size=batch_size,verbose=0)\n",
        "print('Test loss: {:.3f}'.format(test_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oigVJpssKsPq"
      },
      "source": [
        "### **Reduced space visualization**\n",
        "The [**predict**](https://keras.io/api/models/model_training_apis/#predict-method) method of the *encoder* can be used to reduce training, validation and test sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hdz6DzPoiM8g"
      },
      "source": [
        "encoded_train_x = encoder.predict(train_x_flatten)\n",
        "encoded_val_x = encoder.predict(val_x_flatten)\n",
        "encoded_test_x = encoder.predict(test_x_flatten)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVZ87pRrLBF_"
      },
      "source": [
        "The following code visualize the reduced training, validation and test sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtdQa8O8LGdO"
      },
      "source": [
        "plot_2d_data([encoded_train_x,encoded_val_x,encoded_test_x],[train_y,val_y,test_y],['Train','Validation','Test'],(18,6))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxE9Ep4d2E1D"
      },
      "source": [
        "### **Reconstructed images**\n",
        "The **predict** method of the *decoder* can be used to reconstruct the original images from the encoded space. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZ_5pvKW2GRs"
      },
      "source": [
        "decoded_test_x_flatten=decoder.predict(encoded_test_x)\n",
        "\n",
        "print('Decoded test flatten shape: ',decoded_test_x_flatten.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_5Jqw52qCWA"
      },
      "source": [
        "Before visualizing the reconstructed images, it is necessary to return to their original 2D shape."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7G3XiJt2Nyf"
      },
      "source": [
        "decoded_test_x=np.reshape(decoded_test_x_flatten,(test_x.shape[0],test_x.shape[1],test_x.shape[2]))\n",
        "\n",
        "print('Decoded test shape: ',decoded_test_x.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODN5cjj-qcaS"
      },
      "source": [
        "Randomly selected images and the corresponding reconstructed version can be shown executing the following code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxlxdYW9zwpg"
      },
      "source": [
        "n=5\n",
        "\n",
        "fig, axs = plt.subplots(n, 2,figsize=(4,6))\n",
        "axs[0,0].set_title('Original image')\n",
        "axs[0,1].set_title('Autoencoder')\n",
        "for i in range(n):\n",
        "  rnd_idx=random.randint(0,test_x.shape[0]-1)\n",
        "\n",
        "  axs[i,0].axis('off')\n",
        "  axs[i,0].imshow(test_x[rnd_idx], cmap='gray')\n",
        "\n",
        "  axs[i,1].axis('off')\n",
        "  axs[i,1].imshow(decoded_test_x[rnd_idx], cmap='gray')\n",
        "  \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOCfcBtBzxDn"
      },
      "source": [
        "## **Comparison between PCA and autoencoder**\n",
        "The following code visualizes the reconstructed images returned by both PCA and autoencoder starting from images randomly selected from the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpIng6sBY4iC"
      },
      "source": [
        "n=5\n",
        "\n",
        "fig, axs = plt.subplots(n, 3,figsize=(5,8))\n",
        "axs[0,0].set_title('Original image')\n",
        "axs[0,1].set_title('PCA')\n",
        "axs[0,2].set_title('Autoencoder')\n",
        "for i in range(n):\n",
        "  rnd_idx=random.randint(0,test_x.shape[0]-1)\n",
        "\n",
        "  axs[i,0].axis('off')\n",
        "  axs[i,0].imshow(test_x[rnd_idx], cmap='gray')\n",
        "\n",
        "  axs[i,1].axis('off')\n",
        "  axs[i,1].imshow(pca_decoded_test_x[rnd_idx], cmap='gray')\n",
        "\n",
        "  axs[i,2].axis('off')\n",
        "  axs[i,2].imshow(decoded_test_x[rnd_idx], cmap='gray')\n",
        "  \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UoAnIWGqgwA"
      },
      "source": [
        "The images reconstructed by the autoencoder is far better than that obtained with PCA."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fv-j4SrGT53L"
      },
      "source": [
        "# **Image denoising**\n",
        "In this section a convolutional autoencoder is used to solve an image denoising problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOr2j2yRzKfv"
      },
      "source": [
        "## **Dataset**\n",
        "The [**fashion MNIST**](https://github.com/zalandoresearch/fashion-mnist) dataset, containing 28x28 grayscale images of the 10 fashion categories, will be used.\n",
        "\n",
        "The goal is to train the autoencoder to map noisy images to clean ones.\n",
        "\n",
        "The following code loads in memory the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCRNVZrPXzS7"
      },
      "source": [
        "(train_x, _), (test_x, _) = keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTB9pMXc1YXy"
      },
      "source": [
        "### **Visualization**\n",
        "Randomly selected images can be shown by executing the following code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nv6_bRX1chZ"
      },
      "source": [
        "image_count=10\n",
        "\n",
        "_, axs = plt.subplots(1, image_count,figsize=(15, 10))\n",
        "for i in range(image_count):\n",
        "  random_idx=random.randint(0,train_x.shape[0])\n",
        "  axs[i].imshow(train_x[random_idx],cmap='gray')\n",
        "  axs[i].axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RR_iB7718s7"
      },
      "source": [
        "### **Intensity range normalization**\n",
        "As in previous section, a simple normalization step is applied to map values from range [0;255] to range [0;1]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2ntNebXX6Il"
      },
      "source": [
        "print('Min value before normalization: ',train_x.min())\n",
        "print('Max value before normalization: ',train_x.max())\n",
        "\n",
        "train_x = train_x/255.0\n",
        "test_x = test_x/255.0\n",
        "\n",
        "print('Min value after normalization: ',train_x.min())\n",
        "print('Max value after normalization: ',train_x.max())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epZ8ZY0o3Cm9"
      },
      "source": [
        "### **Image shape**\n",
        "To use grayscale images as input of a convolutional autoencoder, it is necessary to add a new unit axis to explicitly represent single channel images.\n",
        "\n",
        "By executing the following code, the shape of the images is updated from WxH to WxHx1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77Ze48hEZAUT"
      },
      "source": [
        "train_x=np.expand_dims(train_x,axis=3)\n",
        "test_x=np.expand_dims(test_x,axis=3)\n",
        "\n",
        "print('Train shape: ',train_x.shape)\n",
        "print('Test shape: ',test_x.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7gUi6o040kh"
      },
      "source": [
        "### **Split data into training and validation sets**\n",
        "In order to avoid overfitting during training, it is necessary to have a separate dataset (called validation set), in addition to the training and test datasets, to choose the optimal value for the hyperparameters.\n",
        "\n",
        "For this reason, *train_x* is divided into training and validation sets using the **train_test_split** function provided by Scikit-learn.\n",
        "\n",
        "The *val_size* variable represents the percentage (or the absolute number) of patterns to include in the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IF0k3I1fDOvi"
      },
      "source": [
        "val_size=10000\n",
        "\n",
        "train_x, val_x = train_test_split(train_x, test_size = val_size,random_state = 1,shuffle=True)\n",
        "\n",
        "print('Train shape: ',train_x.shape)\n",
        "print('Validation shape: ',val_x.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eL-3uTo5oow"
      },
      "source": [
        "### **Synthetic generation of noisy images**\n",
        "To synthetically generate noisy images, a Gaussian noise matrix is applied to the original images. After that, the resulting images are clipped in the range [0;1].\n",
        "\n",
        "Numpy library provides the function [**random.normal**](https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html) to draw random samples from a normal (Gaussian) distribution with mean *loc* and standard deviation *scale*. The parameter *size* represents the shape of the output samples.\n",
        "\n",
        "The strength of the noise applied is represented by the *noise_factor* variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkmWBt9VT8fq"
      },
      "source": [
        "noise_factor = 0.5\n",
        "\n",
        "noisy_train_x = train_x + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=train_x.shape) \n",
        "noisy_val_x = val_x + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=val_x.shape) \n",
        "noisy_test_x = test_x + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=test_x.shape) \n",
        "\n",
        "noisy_train_x = np.clip(noisy_train_x, 0., 1.)\n",
        "noisy_val_x = np.clip(noisy_val_x, 0., 1.)\n",
        "noisy_test_x = np.clip(noisy_test_x, 0., 1.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOGyVznJ9Egm"
      },
      "source": [
        "### **Visualization of noisy images**\n",
        "The following code shows some randomly selected original images and the corresponding noisy ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIqRTxviUekc"
      },
      "source": [
        "image_count=10\n",
        "\n",
        "fig, axs = plt.subplots(2, image_count,figsize=(15,3))\n",
        "for i in range(image_count):\n",
        "  rnd_idx=random.randint(0,train_x.shape[0]-1)\n",
        "\n",
        "  axs[0,i].axis('off')\n",
        "  axs[0,i].imshow(train_x[rnd_idx].reshape(train_x[rnd_idx].shape[0], train_x[rnd_idx].shape[1]), cmap='gray')\n",
        "\n",
        "  axs[1,i].axis('off')\n",
        "  axs[1,i].imshow(noisy_train_x[rnd_idx].reshape(noisy_train_x[rnd_idx].shape[0], noisy_train_x[rnd_idx].shape[1]), cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbuypZoQ9xjm"
      },
      "source": [
        "## **Denoising autoencoder**\n",
        "In this section a convolutional autoencoder is implemented to recover noisy **fashion MNIST** images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Fd6hbWt-VW2"
      },
      "source": [
        "### **Model definition**\n",
        "The following function creates a convolutional autoencoder given:\n",
        "- the shape of the input images (*input_shape*).\n",
        "\n",
        "[**Keras layers API**](https://keras.io/api/layers/) offers a wide range of built-in layers ready for use, including:\n",
        "- [**Input**](https://keras.io/api/layers/core_layers/input/) - the input of the model. Note that, you can also omit the **Input** layer. In that case the model doesn't have any weights until the first call to a training/evaluation method (since it is not yet built);\n",
        "- [**Conv2D**](https://keras.io/api/layers/convolution_layers/convolution2d/) - a 2D convolution layer;\n",
        "- [**MaxPooling2D**](https://keras.io/api/layers/pooling_layers/average_pooling2d/) - a 2D max pooling layer;\n",
        "- [**UpSampling2D**](https://keras.io/api/layers/reshaping_layers/up_sampling2d/) - a 2D upsampling layer. It is an unpooling layer with no trainable parameters useful to upsample 3D volumes previously reduced by convolutional or pooling layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4SAEh3vAL_J"
      },
      "source": [
        "def build_denoising_autoencoder(input_shape=(28, 28, 1)):\n",
        "    autoencoder=keras.Sequential(\n",
        "            [\n",
        "              layers.Input(shape=input_shape),\n",
        "              layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "              layers.MaxPooling2D((2, 2), padding='same'),\n",
        "              layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "              layers.MaxPooling2D((2, 2), padding='same'),\n",
        "              layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "              layers.UpSampling2D((2, 2)),\n",
        "              layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "              layers.UpSampling2D((2, 2)),\n",
        "              layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
        "            ]\n",
        "          )\n",
        "    return autoencoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEu4A5LcBi3G"
      },
      "source": [
        "### **Model creation**\n",
        "The following code creates the denoising autoencoder by calling the **build_denoising_autoencoder** function defined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNfmHppiXgUF"
      },
      "source": [
        "denoising_autoencoder=build_denoising_autoencoder()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_igp0ajBtXE"
      },
      "source": [
        "### **Model visualization**\n",
        "A string summary of the network can be printed by executing the following code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jidtNRa5ZX3a"
      },
      "source": [
        "denoising_autoencoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdsJgQvxB-SO"
      },
      "source": [
        "Alternatively, a plot of the neural network graph can be visualized."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "587GsUelZdlq"
      },
      "source": [
        "keras.utils.plot_model(denoising_autoencoder,show_shapes=True, show_layer_names=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJ4EYJQICimj"
      },
      "source": [
        "### **Model compilation**\n",
        "The following code compiles the model as already done for the undercomplete autoencoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4kTXp5FXevM"
      },
      "source": [
        "denoising_autoencoder.compile(loss='mse',optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiTJFlMkDcsl"
      },
      "source": [
        "### **Training**\n",
        "Now we are ready to train our model by calling the **fit** method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rj13tAOkZsDK"
      },
      "source": [
        "epoch_count = 100\n",
        "batch_size=128\n",
        "patience=5\n",
        "\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
        "\n",
        "history=denoising_autoencoder.fit(noisy_train_x,train_x,validation_data=(noisy_val_x, val_x),epochs=epoch_count,batch_size=batch_size,callbacks=[early_stop])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjfdacBbEIai"
      },
      "source": [
        "The following code calls the **plot_history** function defined above to draw in a graph the loss over epochs on both training and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqTC-Q8ZELO4"
      },
      "source": [
        "plot_history(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPMH0w2R1c1u"
      },
      "source": [
        "## **Performance evaluation on the test set**\n",
        "The performance on the test set can be easily measured by calling the **evaluate** method of the autoencoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZxhDBWF1dK8"
      },
      "source": [
        "test_loss = denoising_autoencoder.evaluate(noisy_test_x, test_x, batch_size=batch_size,verbose=0)\n",
        "print('Test loss: {:.3f}'.format(test_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeyDkLthFdjd"
      },
      "source": [
        "## **Denoised images**\n",
        "The **predict** method can be used to recover the original images from the noisy test set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ymw3VPWa01e"
      },
      "source": [
        "denoised_test_x=denoising_autoencoder.predict(noisy_test_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyeuQiWxGKeV"
      },
      "source": [
        "Randomly selected noisy images and the corresponding denoised version can be shown executing the following code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYVDD4MjbAY7"
      },
      "source": [
        "image_count = 10\n",
        "\n",
        "fig, axs = plt.subplots(3, image_count,figsize=(15,5))\n",
        "for i in range(image_count):\n",
        "  rnd_idx=random.randint(0,test_x.shape[0]-1)\n",
        "\n",
        "  axs[0,i].axis('off')\n",
        "  axs[0,i].imshow(test_x[rnd_idx].reshape(test_x[rnd_idx].shape[0], test_x[rnd_idx].shape[1]), cmap='gray')\n",
        "  \n",
        "  axs[1,i].axis('off')\n",
        "  axs[1,i].imshow(noisy_test_x[rnd_idx].reshape(noisy_test_x[rnd_idx].shape[0], noisy_test_x[rnd_idx].shape[1]), cmap='gray')\n",
        "\n",
        "  axs[2,i].axis('off')\n",
        "  axs[2,i].imshow(denoised_test_x[rnd_idx].reshape(denoised_test_x[rnd_idx].shape[0], denoised_test_x[rnd_idx].shape[1]), cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZardAnq4Ehlq"
      },
      "source": [
        "# **Anomaly detection: credit card fraud**\n",
        "In this section, an autoencoder is used to detect fraudulent credit/debit card transactions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKXKUz_LN39l"
      },
      "source": [
        "## **How use autoencoders to detect anomalies?**\n",
        "An *anomaly* can be defined as an illegitimate data point generated by a different process than whatever generated the rest of the data.\n",
        "\n",
        "By learning to replicate the most salient features in the training data an autoencoder is encouraged to learn to precisely reproduce the most frequently observed characteristics. When facing anomalies, the model should worsen its reconstruction performance.\n",
        "\n",
        "Usually, only data with *normal* instances are used to train the model. After training, the autoencoder will accurately reconstruct *normal* data, while failing to do so with unfamiliar anomalous data. \n",
        "\n",
        "Reconstruction error (the error between the original data and its reconstructed version) is used as an anomaly score to detect anomalies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2SBNw1tFGr8"
      },
      "source": [
        "## **Dataset**\n",
        "The [Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud/) dataset from Kaggle contains 284807 European credit card transactions with 492 fraudulent transactions (0.172% of all transactions). Everything except the time and amount has been reduced by a PCA for privacy concerns.\n",
        "\n",
        "The dataset is stored in a CSV file and can be easily loaded in memory using [**pandas**](https://pandas.pydata.org/), a software library for data manipulation and analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Daa2iUhEm0k8"
      },
      "source": [
        "dataframe = pd.read_csv('creditcard.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VYdGQU4HBwq"
      },
      "source": [
        "The variable *dataframe* is an instance of the pandas class [**DataFrame**](https://pandas.pydata.org/pandas-docs/stable/reference/frame.html), a 2-dimensional labeled data structure with columns of potentially different types."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xc4wWBpJHKr6"
      },
      "source": [
        "### **Visualization**\n",
        "*row_count* randomly selected rows can be shown by executing the following code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAbea04inJZ3"
      },
      "source": [
        "row_count=5\n",
        "\n",
        "dataframe.sample(row_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siHgJfXhHWza"
      },
      "source": [
        "### **Statistics**\n",
        "The [**info**](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.info.html) method can be used to print a brief summary of a **DataFrame** including the index and the type of each column, the non-null values and the memory usage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOgV7HCYnMQM"
      },
      "source": [
        "dataframe.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BfFpFV3HwiR"
      },
      "source": [
        "To show the overall statistics of the dataset can be used the method [**describe**](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uv3-717OHpzr"
      },
      "source": [
        "dataframe.describe().transpose()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obzgZWKYH_oa"
      },
      "source": [
        "The method [**hist**](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.hist.html) draws a histogram for each column in the **DataFrame**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2PRZWrbIDHd"
      },
      "source": [
        "dataframe.hist(bins=50, figsize=(20,15))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYFfbRrGIQs9"
      },
      "source": [
        "From the statistics and the histograms it is clear how each feature presents a very different distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQbDBz6TIu6q"
      },
      "source": [
        "### **Split features from target values**\n",
        "The following code separates the features from the target values (clean/fraudulent transactions)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUVmqIP_oFnU"
      },
      "source": [
        "dataframe_x=dataframe.drop(['Class'],axis=1)\n",
        "dataframe_y=dataframe['Class']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkDxBvjeJXLq"
      },
      "source": [
        "The Numpy representation of a **DataFrame** can be obtained using the [**values**](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.values.html) property."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3JJPnOkomRi"
      },
      "source": [
        "x=dataframe_x.values\n",
        "y=dataframe_y.values\n",
        "\n",
        "print('Feature shape: ',x.shape)\n",
        "print('Target shape: ',y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaSts_YWJx6b"
      },
      "source": [
        "### **Split clean and fraudulent transactions**\n",
        "The following code separates clean and fraudulent transactions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeiDYQvHqOMG"
      },
      "source": [
        "cleans=y==0\n",
        "frauds=y==1\n",
        "\n",
        "clean_x=x[cleans]\n",
        "clean_y=y[cleans]\n",
        "\n",
        "fraud_x=x[frauds]\n",
        "fraud_y=y[frauds]\n",
        "\n",
        "print('Clean feature shape: ',clean_x.shape)\n",
        "print('Clean target shape: ',clean_y.shape)\n",
        "print('Fraudulent feature shape: ',fraud_x.shape)\n",
        "print('Fraudulent target shape: ',fraud_y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGkNN8Rpo5T6"
      },
      "source": [
        "### **Split data into training, validation and test sets**\n",
        "In order to avoid overfitting during training and to evaluate the generalization capabilites of the models, it is necessary to divide the data into three disjoined datasets: training, validation and test sets.\n",
        "\n",
        "For this reason, the data are divided using the **train_test_split** function provided by Scikit-learn.\n",
        "\n",
        "The *test_size* and *val_size* parameters represent the percentage (or the absolute number) of patterns to include in the test and validation sets, respectively. \n",
        "\n",
        "<u>Note that, the autoencoder will be trained using only clean transactions while the test set will contain both clean and fraudulent transactions.</u>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrfzU1-Zo-dq"
      },
      "source": [
        "test_size=0.25\n",
        "val_size=0.33\n",
        "\n",
        "train_x, test_x, train_y, test_y = train_test_split(clean_x, clean_y, test_size = test_size,random_state = 1,shuffle=True)\n",
        "\n",
        "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size = val_size,random_state = 1,shuffle=True)\n",
        "\n",
        "test_x=np.concatenate((test_x, fraud_x))\n",
        "test_y=np.concatenate((test_y, fraud_y))\n",
        "\n",
        "print('Train feature shape: ',train_x.shape)\n",
        "print('Train target shape: ',train_y.shape)\n",
        "print('Validation feature shape: ',val_x.shape)\n",
        "print('Validation target shape: ',val_y.shape)\n",
        "print('Test feature shape: ',test_x.shape)\n",
        "print('Test target shape: ',test_y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlUJU0QPrAmC"
      },
      "source": [
        "### **Data normalization**\n",
        "It is good practice to normalize features that use different scales and ranges.\n",
        "\n",
        "Scikit-learn library provides the class [**StandardScaler**](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) to normalize features by removing the mean and scaling to unit variance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raJty9W5o6Jd"
      },
      "source": [
        "scaler = StandardScaler().fit(train_x)\n",
        "train_x = scaler.transform(train_x)\n",
        "val_x = scaler.transform(val_x)\n",
        "test_x = scaler.transform(test_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CSMdHAwRka-"
      },
      "source": [
        "## **The autoencoder**\n",
        "In this section an autoencoder is trained to detect anomalies into credit card transactions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "or452n77RVo3"
      },
      "source": [
        "### **Model creation**\n",
        "The following code creates the autoencoder by calling the **build_autoencoder** function defined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HS1FQcPzrNtA"
      },
      "source": [
        "autoencoder,encoder,_=build_autoencoder(train_x.shape[1],[24,16,8,4],2,'elu',None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpcJ3Er-SClG"
      },
      "source": [
        "### **Model visualization**\n",
        "A string summary of the network can be printed by executing the following code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUqcbm1aSD82"
      },
      "source": [
        "autoencoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZcoMLOwSXCn"
      },
      "source": [
        "lternatively, a plot of the neural network graph can be visualized."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jtPedgaSaUF"
      },
      "source": [
        "keras.utils.plot_model(autoencoder,show_shapes=True, show_layer_names=False,expand_nested=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rp9qApPfStPm"
      },
      "source": [
        "### **Model compilation**\n",
        "The following code compiles the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyZ-G3iVrTqj"
      },
      "source": [
        "autoencoder.compile(loss='mse',optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWv5UTGwTBCe"
      },
      "source": [
        "### **Training**\n",
        "Now we are ready to train our model by calling the **fit** method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zea_QzWQrfwZ"
      },
      "source": [
        "epoch_count = 200\n",
        "batch_size=256\n",
        "patience=5\n",
        "\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
        "\n",
        "history=autoencoder.fit(train_x,train_x,validation_data=(val_x,val_x),epochs=epoch_count,batch_size=batch_size,callbacks=[early_stop])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6cqF4EGUZEW"
      },
      "source": [
        "The following code calls the **plot_history** function defined above to draw in a graph the loss over epochs on both training and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvGguf88Uabk"
      },
      "source": [
        "plot_history(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ky7ok0AZruA-"
      },
      "source": [
        "## **Latent space visualization**\n",
        "It is always interesting to look at the compressed representation obtained by the autoencoder.\n",
        "\n",
        "The **predict** method of the *encoder* can be used to reduce training, validation and test sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aH3hFuv1rvYA"
      },
      "source": [
        "encoded_train_x = encoder.predict(train_x)\n",
        "encoded_val_x = encoder.predict(val_x)\n",
        "encoded_test_x = encoder.predict(test_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFpkspPKUvHl"
      },
      "source": [
        "The following code visualize training,validation and test sets mapped into the latent space."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngkyENylr9B-"
      },
      "source": [
        "plot_2d_data([encoded_train_x,encoded_val_x,encoded_test_x],[train_y,val_y,test_y],['Train','Validation','Test'],(15,7))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lIFVPKBdiJm"
      },
      "source": [
        "## **Fraud detection**\n",
        "To evaluate the fraud detection capabilities of the model, the MSE between each transaction and its reconstructed version will be used as anomaly score.\n",
        "\n",
        "The following code calls the **predict** method to generate the reconstructed transactions (*reconstructed_train_x*, *reconstructed_val_x* and *reconstructed_test_x*) of the training, validation and test sets (*train_x*, *val_x* and *test_x*)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BFBj9YfdZJf"
      },
      "source": [
        "reconstructed_train_x=autoencoder.predict(train_x)\n",
        "reconstructed_val_x=autoencoder.predict(val_x)\n",
        "reconstructed_test_x=autoencoder.predict(test_x)\n",
        "\n",
        "print('Reconstructed train shape: ',reconstructed_train_x.shape)\n",
        "print('Reconstructed validation shape: ',reconstructed_val_x.shape)\n",
        "print('Reconstructed test shape: ',reconstructed_test_x.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaNCTzBabH9C"
      },
      "source": [
        "Scikit-learn library provides the function [**mean_squared_error**](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) to compute MSE metric."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbJFfiY-dvwu"
      },
      "source": [
        "train_mse=mean_squared_error(train_x.transpose(),reconstructed_train_x.transpose(),multioutput='raw_values')\n",
        "val_mse=mean_squared_error(val_x.transpose(),reconstructed_val_x.transpose(),multioutput='raw_values')\n",
        "test_mse=mean_squared_error(test_x.transpose(),reconstructed_test_x.transpose(),multioutput='raw_values')\n",
        "\n",
        "print('Train MSE shape: ',train_mse.shape)\n",
        "print('Validation MSE shape: ',val_mse.shape)\n",
        "print('Test MSE shape: ',test_mse.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "is04tIQhBtnE"
      },
      "source": [
        "### **Distribution of means squared error**\n",
        "The following code draws the MSE distributions of training, validation and test sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvEGptTTejqn"
      },
      "source": [
        "_, axs = plt.subplots(1,3,figsize=(15,5))\n",
        "\n",
        "axs[0].hist(train_mse, bins=100, density=True, label=\"clean\", alpha=.6, color=\"green\")\n",
        "axs[0].set_title('Train')\n",
        "\n",
        "axs[1].hist(val_mse, bins=100, density=True, label=\"clean\", alpha=.6, color=\"green\")\n",
        "axs[1].set_title('Validation')\n",
        "\n",
        "axs[2].hist(test_mse[(test_y==0).squeeze()], bins=100, density=True, label=\"clean\", alpha=.6, color=\"green\")\n",
        "axs[2].hist(test_mse[(test_y==1).squeeze()], bins=100, density=True, label=\"fraudulent\", alpha=.6, color=\"red\")\n",
        "axs[2].set_title('Test')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jj8wiaz0cYic"
      },
      "source": [
        "Looking at the test distribution, although some fraudulent transactions present a low MSE very similar to clean transactions, in general the fraudulent transactions clearly have a distinguishing element in their data that sets them apart from clean ones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD_SY7-XDGNF"
      },
      "source": [
        "### **Detection accuracy**\n",
        "To detect fraudulent transactions a threshold on the MSE value can be used. \n",
        "\n",
        "It must be chosen to limit as much as possible the amount of clean transactions classified as fraudulent (i.e., false positive) and to capture the most anomalous ones.\n",
        "\n",
        "Here we select as threshold the MSE value to obtain a specific percentage of true negatives on the validation set. \n",
        "\n",
        "The MSE value corresponding to a specific percentage (*clean_acceptance_rate*) of true negatives (i.e., clean transactions correctly classified) on the validation set is chosen as threshold."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTj4a1LEDRql"
      },
      "source": [
        "clean_acceptance_rate=0.99\n",
        "\n",
        "sorted_val_mse=np.sort(val_mse)\n",
        "\n",
        "idx=int(clean_acceptance_rate*len(sorted_val_mse))\n",
        "\n",
        "thr=sorted_val_mse[int(clean_acceptance_rate*len(sorted_val_mse))]\n",
        "\n",
        "print('Anomaly detection threshold: {:.3f}'.format(thr))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bohGKXmk3xV"
      },
      "source": [
        "The accuracy can be easily measured by calling the [**accuracy_score**](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) method provided by the Scikit-learn library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gz1KyNPSiyrm"
      },
      "source": [
        "train_y_pred=train_mse>thr\n",
        "val_y_pred=val_mse>thr\n",
        "test_y_pred=test_mse>thr\n",
        "\n",
        "train_accuracy=accuracy_score(train_y,train_y_pred,normalize='true')\n",
        "val_accuracy=accuracy_score(val_y,val_y_pred,normalize='true')\n",
        "test_accuracy=accuracy_score(test_y,test_y_pred,normalize='true')\n",
        "\n",
        "print('Train accuracy: {:.3f}'.format(train_accuracy))\n",
        "print('Validation accuracy: {:.3f}'.format(val_accuracy))\n",
        "print('Test accuracy: {:.3f}'.format(test_accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQ0KqnvZlmvh"
      },
      "source": [
        "### **Confusion matrix**\n",
        "To evaluate the classification accuracy in presence of an unbalanced dataset, it is useful to compute the [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix).\n",
        "\n",
        "Scikit-learn library provides the function [**confusion_matrix**](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) to compute the confusion matrix given the grouhd truth (*test_y*) and the predicted classes (*test_y_pred*) as input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkG6N3mBGS4Q"
      },
      "source": [
        "conf_matrix=confusion_matrix(test_y, test_y_pred, normalize='true')\n",
        "print(conf_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZOQTm-onPxu"
      },
      "source": [
        "The following code visualizes the 2D confusion matrix as a color-coded image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDIVaNwinSrd"
      },
      "source": [
        "show_confusion_matrix(conf_matrix,('clean','fraud'),figsize=(6,6))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfAtUFB8oz6u"
      },
      "source": [
        "# **Exercise**\n",
        "Solve another anomaly detection problem chosen from:\n",
        "- [Unsupervised Anomaly Detection Benchmark](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/OPQMVF);\n",
        "- [Outlier Detection DataSets](http://odds.cs.stonybrook.edu/)."
      ]
    }
  ]
}